<meta name="referrer" content="no-referrer"/>
> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/Alzc-1xzirH_ky2Diq_rYw)

近期一篇关于康奈尔大学关于 LLM 代理可自主入侵网站的论文是值得网安同学关注。

![](https://mmbiz.qpic.cn/mmbiz_png/R3h5SuP8QnLVutDyzKC7cg0pvRph5OtsnicERKyrRsiaJLqMic064W2XLj1d5pv7s5DHs6ia1Rb6RPuwb6SPLwax6A/640?wx_fmt=png&from=appmsg)

这篇论文的研究展示了 LLM 代理可以自主入侵网站，通过使用 GPT-4 模型在没有人工反馈的情况下执行像盲数据库架构提取和 SQL 注入一样复杂的任务。重要的是，代理不需要事先知道漏洞。也就是说 GPT-4 能够进行此类黑客攻击。研究人员通过 GPT-4 能够在野外自主查找网站中的漏洞。

实验的设置为在沙箱网站上测试了 15 种漏洞，包括简单的 SQL 注入到复杂的 XSS 和 CSRF 攻击。其中定义每个漏洞的目标，并在 10 分钟内执行攻击，成功定义为代理在 5 次尝试中至少成功一次。

使用 GPT-4 进行自主黑客攻击的成本（每次尝试约 $4.19）低于网络安全分析师的成本（每次尝试约 $80）。

试想一下，我们平时给客户用的漏扫设备，替换成具备这种自主入侵网站的大模型设备，在业务实施的前线就不需要这么多高级的工程师了。

然而这样的大模型已经有开源版本，同时在基准测试中已经接近于 GPT-4o 的水平。  

*   **CodeAstra-7B**
    

![](https://mmbiz.qpic.cn/mmbiz_png/R3h5SuP8QnJ7Ca4wSVMX8Ga2BJba5pgLfgW0I0KhOnllgAbSW0aWNoKFxlpdic7nOIEicN8gkWC18mJUJvWq4Ntg/640?wx_fmt=png&from=appmsg)

rootxhacker/CodeAstra-7B 是目前开源最先进的漏洞检测大模型。

```
https://huggingface.co/rootxhacker/CodeAstra-7B

```

![](https://mmbiz.qpic.cn/mmbiz_png/R3h5SuP8QnLVutDyzKC7cg0pvRph5Ots2x25UBffzIxhFfYYo4LouYemP70OGwXZT4H5NiamPDaGGHbRzPfbCtA/640?wx_fmt=png&from=appmsg)

可以看到 CodeAstra-7b 在漏洞检测准确性方面接近于达到 gpt4o 的水平，它是基于强大得 Mistral-7B-Instruct-v0.2 针对多种编程语言中的漏洞检测进行微调训练出来。

**局限性**

*   该模型可能无法捕获所有漏洞或代码质量问题，应用作全面的安全和代码审查策略的一部分。
    
*   如果同一代码片段中存在多个漏洞（两个或三个），则模型可能无法正确识别所有漏洞。
    
*   可能会出现误报，结果应由人工专家验证。
    
*   模型的性能可能会因所分析代码的复杂性和上下文而异。
    
*   CodeAstra 的性能取决于输入代码片段的长度。